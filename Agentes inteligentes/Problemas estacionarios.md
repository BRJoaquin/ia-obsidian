
En un problema estacionario, las probabilidades de transición y las funciones de recompensa no cambian con el tiempo. Esto significa que la política óptima también es constante en el tiempo. Los métodos clásicos de aprendizaje por refuerzo, como Q-learning y SARSA, asumen por defecto que están lidiando con problemas estacionarios. Esta es una suposición fuerte y no siempre realista, pero hace que los problemas sean mucho más manejables.

Un ejemplo de un problema estacionario podría ser un juego de mesa como el ajedrez.
Las reglas del juego (que determinan las probabilidades de transición) y el objetivo del juego (que determina las recompensas) no cambian con el tiempo.
