La entropía también es una medida de la impureza, la incertidumbre o el desorden dentro de un conjunto de instancias. Al igual que el índice de Gini, se utiliza para decidir dónde dividir los datos en un árbol de decisión. Un conjunto de datos que contiene instancias de una sola clase tiene una entropía de 0 (puro), mientras que un conjunto de datos que contiene una mezcla equitativa de clases tiene la máxima entropía. La meta en un árbol de decisión es realizar divisiones de tal manera que se minimice la entropía.