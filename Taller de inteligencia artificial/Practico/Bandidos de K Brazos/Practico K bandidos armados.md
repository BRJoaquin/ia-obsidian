# Datos 

Se utilizo el siguiente [repositorio](https://github.com/JKCooper2/gym-bandits ), para poder mapear los diferentes ambientes. Es decir la cantidad de brazos, su valor optimo ($q^*$) y la distribución de recompensa.

El repositorio de gym-bandits proporciona una serie de entornos de bandit multi-brazos con diferentes características, como distribuciones de recompensa no estacionarias, recompensas con dependencia temporal y estructuras de recompensa no lineales. Estos entornos pueden ser útiles para probar y comparar diferentes algoritmos de aprendizaje por refuerzo en un problema de bandit multi-brazos.

Nos centramos en paricular con el "BanditTenArmedGaussian-v0" que es el mencionado en el libro de S&B

# Framework

El repositorio [https://github.com/openai/gym](https://github.com/openai/gym) es el repositorio oficial de OpenAI Gym, una plataforma de aprendizaje por refuerzo que proporciona una colección de entornos de prueba predefinidos para que los desarrolladores puedan probar y comparar diferentes algoritmos de aprendizaje por refuerzo.

El repositorio contiene la implementación de la plataforma OpenAI Gym, que permite a los desarrolladores crear y evaluar algoritmos de aprendizaje por refuerzo en una variedad de entornos, incluyendo problemas de control de robots, juegos, problemas de toma de decisiones y muchos otros.

