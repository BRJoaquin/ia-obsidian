# Datos 

Se utilizo el siguiente [repositorio](https://github.com/JKCooper2/gym-bandits ), para poder mapear los diferentes ambientes. Es decir la cantidad de brazos, su valor optimo ($q^*$) y la distribución de recompensa.

El repositorio de gym-bandits proporciona una serie de entornos de bandit multi-brazos con diferentes características, como distribuciones de recompensa no estacionarias, recompensas con dependencia temporal y estructuras de recompensa no lineales. Estos entornos pueden ser útiles para probar y comparar diferentes algoritmos de aprendizaje por refuerzo en un problema de bandit multi-brazos.

# Framework